{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Перекрёстная проверка(Кросс-валидация)\n",
    "Перекрёстная проверка является важной темой в `Машинном обучении`, чтобы гарантировать, что наша модель достаточно надежна. Традиционная стратегия обучения использует 3 части набора данных для обучения, тестирования и проверки.\n",
    "\n",
    "* обучающий набор — используется для обучения модели и оптимизации гиперпараметров модели\n",
    "* тестовый набор — используется для оценки того, что модель достаточно обобщает, чтобы правильно работать на данных, на которых она не обучалась. Однако через человека, выполняющего оптимизацию, некоторые знания о тестовом наборе в конечном итоге просачиваются в модель.\n",
    "* проверочный набор — по этой причине мы используем проверочный набор, который используется в качестве окончательной проверки того, что модель способна обобщать ранее неизвестные данные.\n",
    "\n",
    "Создание таких наборов ограничивает количество данных, используемых для обучения, и это может снизить способность модели к обучению. Перекрестная проверка позволяет создать надежную модель, разделив обучающие данные на `k` подмножеств. Каждое подмножество использует часть своих данных для обучения, а часть - для тестирования. Следующее подмножество использует другое разделение обучающих и тестовых данных, как вы можете видеть на рисунке ниже. Это более ресурсоемко, но позволяет использовать данные режима для обучения.\n",
    "\n",
    "![\"Cross validation folds\"](Cross_Validation.jpg)\n",
    "\n",
    "Вы также можете быть уверены, что ваша модель способна обобщать, если каждая из групп имеет схожую производительность. Если одна (или несколько) групп действительно достигают результата, а другие работают плохо, вам нужно больше думать о том, как вы разделяете данные. Вы увидите примеры этого ниже.\n",
    "\n",
    "`Scikit Learn` предлагает множество методов, которые помогают разделить данные на наборы для обучения, тестирования и проверки. Наиболее популярными из тех, которые мы рассмотрим в этом руководстве, являются:\n",
    "\n",
    "* train_test_split — создает единое разделение на обучающий и тестовый наборы.\n",
    "* Kfold — создает k-кратные разделения, позволяющие проводить перекрестную проверку\n",
    "* StratifiedKFold — создает k-кратные разделения, учитывая распределение целевой переменной\n",
    "* cross_val_score — оценка модели evaluta через перекрестную проверку\n",
    "\n",
    "Однако следует помнить, что перекрестная проверка подходит не для всех случаев, и следует с умом подходить к вопросу разделения данных.\n",
    "\n",
    "Подробнее о перекрестной проверке:\n",
    "* https://scikit-learn.org/stable/modules/cross_validation.html\n",
    "* https://en.wikipedia.org/wiki/Cross-validation_(statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте рассмотрим несколько реальных вариантов использования. Сначала мы разделим простой **диапазон из 25 чисел**, а затем рассмотрим популярный **набор данных по ирисам**, который использует измерения лепестков и чашелистиков для прогнозирования вида цветка ириса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, cross_validate, cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rn = range(1,26)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем с метода Kfold, который разбивает обучающий набор на k-кратные выборки, так что каждый образец используется один раз для тестирования и k-1 раз для обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# чтобы продемонстрировать, как разделяются данные, мы создадим 3 и 5 групп.\n",
    "# Функция KFold должна быть применена к данным, и она возвращает местоположение (индекс) обучающей и тестовой выборок.\n",
    "kf5 = KFold(n_splits=5, shuffle=False)\n",
    "kf3 = KFold(n_splits=3, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция Kfold возвращает индексы данных. Наш диапазон от 1 до 25, поэтому индекс равен 0-24\n",
    "for train_index, test_index in kf3.split(rn):\n",
    "    print(train_index, test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтобы получить значения из наших данных, мы используем np.take() для доступа к значению по определенному индексу\n",
    "for train_index, test_index in kf3.split(rn):\n",
    "    print(np.take(rn,train_index), np.take(rn,test_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Диаграмма разделения перекрестной проверки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Давайте разделим наш тестовый диапазон на 5 и 3 части и отобразим разделения на диаграмме.\n",
    "# Чтобы четко показать, какие данные принадлежат каждому набору, мы сдвинем значения на -.1 и +.1\n",
    "# первая часть будет содержать значения 0.9 в обучающем наборе и 1.1 в тестовом наборе, вторая 1.9 и 2.1 и т. д.\n",
    "# мы также дадим каждому набору разный цвет\n",
    "# поскольку мы повторим это упражнение для перемешанной версии, создадим функцию\n",
    "\n",
    "def kfoldize(kf, rn, shift=.1):\n",
    "    train = pd.DataFrame()\n",
    "    test = pd.DataFrame()\n",
    "    i = 1\n",
    "    for train_index, test_index in kf.split(rn):\n",
    "        train_df = pd.DataFrame(np.take(rn, train_index), columns=[\"x\"])\n",
    "        train_df[\"val\"] = i - shift\n",
    "        train = train._append(train_df)\n",
    "\n",
    "        test_df = pd.DataFrame(np.take(rn, test_index), columns=[\"x\"])\n",
    "        test_df[\"val\"] = i + shift\n",
    "        test = test._append(test_df)\n",
    "        i += 1\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train5, test5 = kfoldize(kf5,rn)\n",
    "train3, test3 = kfoldize(kf3,rn)\n",
    "\n",
    "fig,ax = plt.subplots(1,2, figsize=(15,5))\n",
    "ax[0].scatter(x=\"x\",y=\"val\",c=\"b\",label=\"train\",s=15,data=train5)\n",
    "ax[0].scatter(x=\"x\",y=\"val\",c=\"r\",label=\"test\",s=15,data=test5)\n",
    "ax[1].scatter(x=\"x\",y=\"val\",c=\"b\",label=\"train\",s=15,data=train3)\n",
    "ax[1].scatter(x=\"x\",y=\"val\",c=\"r\",label=\"test\",s=15,data=test3)\n",
    "ax[0].set_ylabel(\"Kfold\")\n",
    "ax[0].set_xlabel(\"feature\")\n",
    "ax[1].set_xlabel(\"feature\")\n",
    "ax[0].set_title(\"5 Folds\")\n",
    "ax[1].set_title(\"3 Folds\")\n",
    "plt.suptitle(\"Kfold split between train and test features\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Давайте удостоверимся, как значения распределены между наборами; Также мы создадим функцию, чтобы мы могли повторять\n",
    "def kfold_stats(df, name):\n",
    "    s =  pd.Series({\"Min value: \": df[\"x\"].min(),\n",
    "              \"Max value: \": df[\"x\"].max(),\n",
    "              \"Min occurance: \": df[\"x\"].value_counts().min(),\n",
    "              \"Max occurance: \": df[\"x\"].value_counts().max(),\n",
    "               \"Min lenght\": df.groupby(\"val\").count().min().values[0],\n",
    "               \"Max lenght\": df.groupby(\"val\").count().max().values[0]})\n",
    "    s.name = name\n",
    "    return s\n",
    "pd.concat([kfold_stats(train5, \"Train5\"), kfold_stats(test5,\"Test5\"),\n",
    "          kfold_stats(train3, \"Train3\"), kfold_stats(test3,\"Test3\")], \n",
    "          axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В таблице выше приведены некоторые ключевые факты о KFold:\n",
    "\n",
    "* `Мин. и макс. значение` (Min and Max value) - и обучающий, и тестовый наборы охватывают все признаки\n",
    "* `Мин. и макс. вхождение` (Min and Max occurrence) - каждое значение встречается один раз в тестовом наборе и k-1 раз в обучающем наборе\n",
    "* `Длина мин. и макс. значения` (Min and Max value length) - в случае, если у вас есть число признаков, которое не делится на n, некоторые из них будут иметь разное разделение между тестовым и обучающим наборами. Например, в случае 25 признаков и 3 разделений соотношения будут следующими: 16/9, 17/8, 17/8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffled KFold (Перемешанный KFold)\n",
    "В предыдущем примере вы видели неперемешанное распределение train/test. Такое распределение может повлиять на результат модели машинного обучения, поэтому часто бывает полезно случайным образом разделить признаки, чтобы доказать возможности вашей модели. Случайное разделение данных достигается параметром `shuffle`. Параметр `random-state` инициирует случайность таким образом, что использование того же случайного состояния обеспечивает то же разделение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf42 = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "kf123 = KFold(n_splits=5, shuffle=True, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train42, test42 = kfoldize(kf42,rn)\n",
    "train123, test123 = kfoldize(kf123,rn)\n",
    "train123_2, test123_2 = kfoldize(kf123,rn,shift=.25)\n",
    "\n",
    "fig,ax = plt.subplots(1,2, figsize=(15,5))\n",
    "ax[0].scatter(x=\"x\",y=\"val\",c=\"b\",label=\"train\",s=15,data=train42) \n",
    "ax[0].scatter(x=\"x\",y=\"val\",c=\"r\",label=\"test\",s=15,data=test42)\n",
    "ax[1].scatter(x=\"x\",y=\"val\",c=\"b\",label=\"train\",s=15,data=train123)\n",
    "ax[1].scatter(x=\"x\",y=\"val\",c=\"r\",label=\"test\",s=15,data=test123)\n",
    "ax[1].scatter(x=\"x\",y=\"val\",c=\"k\",label=\"test second run\",s=15,data=test123_2)\n",
    "ax[0].set_ylabel(\"Kfold\")\n",
    "ax[0].set_xlabel(\"feature\")\n",
    "ax[0].set_title(\"Shuffled KFold with random state 42\")\n",
    "ax[1].set_ylabel(\"Kfold\")\n",
    "ax[1].set_xlabel(\"feature\")\n",
    "ax[1].set_title(\"Shuffled KFold with random state 123\")\n",
    "plt.suptitle(\"Shuffled KFold\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kfold на реальном наборе данных\n",
    "Давайте используем Kfold для оценки модели классификации на популярном наборе данных Iris. Он содержит 150 измерений размеров лепестков и чашелистиков 3 разновидностей цветка ириса - setosa, versicolor и virginica. Каждый содержит 50 измерений в наборе.\n",
    "\n",
    "Набор данных Iris на scikit-learn: https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris(return_X_y=False)\n",
    "iris_df = pd.DataFrame(data=iris.data,columns=iris.feature_names)\n",
    "features = iris['feature_names']\n",
    "iris_df['target'] = iris.target\n",
    "iris_df[\"target_name\"] = iris_df['target'].map({i:name for i,name in enumerate(iris.target_names)})\n",
    "iris_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Давайте посмотрим, сколько образцов каждого типа ирисов есть в нашем наборе.\n",
    "pd.DataFrame(iris_df.groupby(\"target_name\").size().reset_index()).rename(columns={0:\"samples\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single fold (одинарная группа)\n",
    "Давайте выполним логистическую регрессию с использованием традиционной функции train_test_split, которая разделит данные на обучающий и тестовый наборы так, чтобы каждое целевое значение встречалось как в обучающем, так и в тестовом наборах одинаковое количество раз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver=\"liblinear\", multi_class=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Логистическая регрессия без Kfold, просто разделенная на 80% обучающего и 20% тестового набора\n",
    "X = iris_df[features]\n",
    "y = iris_df[\"target\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train) \n",
    "pd.DataFrame({\"Accurancy on Train\":[accuracy_score(y_train, model.predict(X_train))],\n",
    "    \"Accurancy on Test\":[accuracy_score(y_test, model.predict(X_test))]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KFold\n",
    "Метод Kfold возвращает порядок образцов, выбранных для обучающих и тестовых наборов в каждой свертке. В кадре данных pandas мы используем функцию .iloc для получения правильных строк. Поскольку мы не разделяем данные на X (features) и y (target), также нужно использовать .loc, чтобы выбрать правильные столбцы (.loc[:,features]) или просто выбрать столбец (['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "for train_index, test_index in kf3.split(iris_df):\n",
    "    X_train = iris_df.iloc[train_index].loc[:, features]\n",
    "    X_test = iris_df.iloc[test_index][features]\n",
    "    y_train = iris_df.iloc[train_index].loc[:,'target']\n",
    "    y_test = iris_df.loc[test_index]['target']\n",
    "        \n",
    "    model.fit(X_train, y_train)\n",
    "    print(f\"Accuracy for the fold no. {i} on the test set: {accuracy_score(y_test, model.predict(X_test))}\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но почему точность в каждой группе **0.0**? Причина в однородности разделений. Поскольку данные упорядочены так, что **setosa** появляется в первых пятидесяти строках набора данных, за которыми следуют **versicolor** и **virginica**, мы добились уникального распределения обучающего набора, что он не содержит никакой цели, ожидаемой в тестовом наборе. Большинство моделей машинного обучения не могут научиться классифицировать класс, который они никогда не видели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name = iris_df[\"target\"]\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(13,3), sharey=True)\n",
    "for i, (train_index, test_index) in enumerate(kf3.split(iris_df)):\n",
    "    ax[i].scatter(x=train_index,y=target_name.iloc[train_index],label =\"train\", c='b')\n",
    "    ax[i].scatter(x=test_index,y=target_name.iloc[test_index], label = \"test\", c='r')\n",
    "    ax[i].set_title(f\"Fold {i+1}\")\n",
    "\n",
    "ax[0].set_yticks([0,1,2])\n",
    "ax[0].set_yticklabels(iris[\"target_names\"])\n",
    "plt.legend(bbox_to_anchor=(1.05, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffled KFold\n",
    "Один из способов обойти эту проблему — использовать перемешанный Kfold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=123)\n",
    "i = 1\n",
    "\n",
    "for train_index, test_index in kf.split(iris_df):\n",
    "    X_train = iris_df.iloc[train_index].loc[:, features]\n",
    "    X_test = iris_df.iloc[test_index].loc[:,features]\n",
    "    y_train = iris_df.iloc[train_index].loc[:,'target']\n",
    "    y_test = iris_df.loc[test_index].loc[:,'target']\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"Accuracy for the fold no. {i} on the test set: {accuracy_score(y_test, y_pred)}\")\n",
    "    \n",
    "    s_train = iris_df.iloc[train_index].loc[:,'target_name'].value_counts()\n",
    "    s_train.name = f\"train {i}\"\n",
    "    s_test = iris_df.iloc[test_index].loc[:,'target_name'].value_counts()\n",
    "    s_test.name = f\"test {i}\"\n",
    "    df = pd.concat([s_train, s_test], axis=1, sort=False)\n",
    "    df[\"|\"] = \"|\"\n",
    "    dfs.append(df)\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=y_train.index,y=iris_df.iloc[train_index].loc[:,'target_name'],label =\"train\")\n",
    "plt.scatter(x=y_test.index,y=iris_df.iloc[test_index].loc[:,'target_name'], label = \"test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that now we pick samples from all three types of irises, however some are chosen more often than others. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(dfs,axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified KFold (стратифицированный KFold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вместо использования случайного Kfold мы можем использовать StratifiedKFold, которому нужен дополнительный параметр `y`. В качестве `y` вы используете целевую переменную, чтобы Kfold и выбрал сбалансированное распределение целей в каждой группе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "kf = StratifiedKFold(n_splits=3, shuffle=True, random_state=123)\n",
    "i = 1\n",
    "for train_index, test_index in kf.split(iris_df, iris_df[\"target\"]):\n",
    "    X_train = iris_df.iloc[train_index].loc[:, features]\n",
    "    X_test = iris_df.iloc[test_index].loc[:,features]\n",
    "    y_train = iris_df.iloc[train_index].loc[:,'target']\n",
    "    y_test = iris_df.loc[test_index].loc[:,'target']\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    print(f\"Accuracy for the fold no. {i} on the test set: {accuracy_score(y_test, model.predict(X_test))}, doublecheck: {model.score(X_test,y_test)}\")\n",
    "    \n",
    "    s_train = iris_df.iloc[train_index].loc[:,'target_name'].value_counts()\n",
    "    s_train.name = f\"train {i}\"\n",
    "    s_test = iris_df.iloc[test_index].loc[:,'target_name'].value_counts()\n",
    "    s_test.name = f\"test {i}\"\n",
    "    df = pd.concat([s_train, s_test], axis=1, sort=False)\n",
    "    df[\"|\"] = \"|\"\n",
    "    dfs.append(df)\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=y_train.index,y=iris_df.iloc[train_index].loc[:,'target_name'],label =\"train\")\n",
    "plt.scatter(x=y_test.index,y=iris_df.iloc[test_index].loc[:,'target_name'], label = \"test\")\n",
    "plt.legend()\n",
    "plt.title(\"Shuffled stratified StratifiedKFold - 3rd Fold\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(dfs,axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Перекрестная проверка без KFold\n",
    "Если вы не хотите экспериментировать с разделенными данными, вам не нужно использовать KFolds, cross_validate или cross_val_score проведут обучение, используя ваши данные и предпочитаемое количество разделений, и выдадут вам оценку на тестовом наборе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_validate позволяет указать метрики, которые вы хотите видеть\n",
    "for i, score in enumerate(cross_validate(model, X,y, cv=3)[\"test_score\"]):\n",
    "    print(f\"Accuracy for the fold no. {i} on the test set: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, score in enumerate(cross_val_score(model, X,y, cv=3)):\n",
    "    print(f\"Accuracy for the fold no. {i} on the test set: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Как распределены входные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтобы увидеть, как KFold распределяет признаки, давайте взглянем на набор данных Titanic.\n",
    "# https://www.kaggle.com/c/titanic\n",
    "titanic = pd.read_csv(r'titanic.csv').sort_values(by=\"Sex\").reset_index(drop=True)\n",
    "dfs = []\n",
    "dfs_data = []\n",
    "\n",
    "kf = StratifiedKFold(n_splits=3, shuffle=False) #, random_state=123\n",
    "i = 1\n",
    "for train_index, test_index in kf.split(titanic, titanic[\"Survived\"]):\n",
    "    X_train = titanic.iloc[train_index].drop(columns=[\"Survived\"])\n",
    "    X_test = titanic.iloc[test_index].drop(columns=[\"Survived\"])\n",
    "    y_train = titanic.iloc[train_index].loc[:,\"Survived\"]\n",
    "    y_test = titanic.loc[test_index].loc[:,\"Survived\"]\n",
    "    \n",
    "    dfs_data.append({\"train\": pd.concat([X_train,y_train], axis=1, sort=False), \"test\": pd.concat([X_test,y_test], axis=1, sort=False)})\n",
    "    \n",
    "    #model.fit(X_train, y_train)\n",
    "    #print(f\"Accuracy for the fold no. {i} on the test set: {accuracy_score(y_test, model.predict(X_test))}, doublecheck: {model.score(X_test,y_test)}\")\n",
    "       \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя StratifiedKFold, мы ожидаем, что соотношение выживших и жертв будет одинаковым как в обучающем, так и в тестовом наборе данных. Глядя на распределение и графики, это ожидание, похоже, оправдывается."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics = []\n",
    "for i, data in enumerate(dfs_data):\n",
    "    for st in [\"train\",\"test\"]:\n",
    "        s = data[st][[\"Survived\"]].groupby([\"Survived\"]).size()\n",
    "        s.index = s.index.map({0:\"Died\",1:\"Survived\"})\n",
    "        s.name = f\"{st} - {i+1}\"\n",
    "        statistics.append(s)\n",
    "\n",
    "pd.concat(statistics, axis=1).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(dfs_data):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(15, 5), sharey=True)\n",
    "    \n",
    "    plot_df_train = dfs_data[i][\"train\"][[\"Survived\"]].groupby([\"Survived\"]).size()\n",
    "    plot_df_train.index = plot_df_train.index.map({0: \"Died\", 1: \"Survived\"})\n",
    "    sns.barplot(x=plot_df_train.index, y=plot_df_train.values, ax=ax[0])\n",
    "    ax[0].set_title(f\"Train set - {i + 1} fold\")\n",
    "    ax[0].set_xlabel('')\n",
    "    \n",
    "    plot_df_test = dfs_data[i][\"test\"][[\"Survived\"]].groupby([\"Survived\"]).size()\n",
    "    plot_df_test.index = plot_df_test.index.map({0: \"Died\", 1: \"Survived\"})\n",
    "    sns.barplot(x=plot_df_test.index, y=plot_df_test.values, ax=ax[1])\n",
    "    ax[1].set_title(f\"Test set - {i + 1} fold\")\n",
    "    ax[1].set_xlabel('')\n",
    "    \n",
    "    plt.suptitle(\"Stratification works perfectly for the target variable\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако StratifiedKFold вообще не смотрит на распределение входных признаков. Мы отсортировали входные данные по полу, чтобы продемонстрировать это `.sort_values(by=\"Sex\")`. Как вы можете видеть, соотношение полов в обучающем и тестовом наборах не очень хорошо коррелирует, что может быть проблемой, поскольку у Female гораздо больше шансов, чтобы пережить эту катастрофу. Если ваш тестовый набор содержит в основном мужчин, модель может ожидать гораздо более высокий уровень смертности. Если наоборот, модель может стать очень оптимистичной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# таблица, показывающая распределение полов в разделении StratifiedKFold\n",
    "metric_dfs = []\n",
    "for i, data in enumerate(dfs_data):\n",
    "    s = dfs_data[i][\"train\"].groupby(\"Sex\").size()\n",
    "    s.name = f\"Fold {i+1} Train\"\n",
    "    st = dfs_data[i][\"test\"].groupby(\"Sex\").size()\n",
    "    st.name = f\"Fold {i+1} Test\"\n",
    "    metric_df = pd.concat([s,st],axis=1)\n",
    "    metric_df[\"|\"] = \"|\"\n",
    "    metric_dfs.append(metric_df)\n",
    "pd.concat(metric_dfs,axis=1).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(dfs_data):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(15, 5), sharey=True)\n",
    "\n",
    "    train_plot_df = data[\"train\"][\"Sex\"].value_counts()\n",
    "    sns.barplot(x=train_plot_df.index, y=train_plot_df.values, ax=ax[0])\n",
    "    ax[0].set_title(f\"Train set - {i + 1} fold\")\n",
    "\n",
    "    test_plot_df = data[\"test\"][\"Sex\"].value_counts()\n",
    "    sns.barplot(x=test_plot_df.index, y=test_plot_df.values, ax=ax[1])\n",
    "    ax[1].set_title(f\"Test set - {i + 1} fold\")\n",
    "\n",
    "    plt.suptitle(\"Stratification doesn't consider distribution of the features\")\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])  # Adjust layout for suptitle\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовка идеального распределения признаков — довольно сложная задача, особенно если у вас большое количество признаков, и вы хотите обучить и протестировать модель, учитывая все основные комбинации признаков. Мы не можем рассмотреть, как решить балансировку признаков в этой работе, но если бы вы использовали перемешанный StratifiedKFold, распределение было бы лучше. Вы должны знать об этом при построении своей модели, но хорошая новость в том, что перекрестная проверка может помочь вам определить, что что-то не так, если оценка модели значительно отличается в некоторых группах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Давайте рассмотрим другие методы перекрестной проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeated KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "kf42 = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "krf42 = RepeatedKFold(n_splits=3, n_repeats=2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train42, test42 = kfoldize(kf42,rn)\n",
    "train123, test123 = kfoldize(krf42,rn)\n",
    "#train123_2, test123_2 = kfoldize(kf123,rn,shift=.25)\n",
    "\n",
    "fig,ax = plt.subplots(1,2, figsize=(15,5), sharey=True)\n",
    "ax[0].scatter(x=\"x\",y=\"val\",c=\"b\",label=\"train\",s=15,data=train42) \n",
    "ax[0].scatter(x=\"x\",y=\"val\",c=\"r\",label=\"test\",s=15,data=test42)\n",
    "ax[1].scatter(x=\"x\",y=\"val\",c=\"b\",label=\"train\",s=15,data=train123)\n",
    "ax[1].scatter(x=\"x\",y=\"val\",c=\"r\",label=\"test\",s=15,data=test123)\n",
    "#ax[1].scatter(x=\"x\",y=\"val\",c=\"k\",label=\"test second run\",s=15,data=test123_2)\n",
    "ax[0].set_ylabel(\"Kfold\")\n",
    "ax[0].set_xlabel(\"feature\")\n",
    "ax[0].set_title(\"Shuffled KFold with random state 42\")\n",
    "ax[1].set_ylabel(\"Kfold\")\n",
    "ax[1].set_xlabel(\"feature\")\n",
    "ax[1].set_title(\"RepeatedKFold with random state 42\")\n",
    "plt.suptitle(\"Shuffled Repeated KFold\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ShuffleSplit\n",
    "https://scikit-learn.org/stable/modules/cross_validation.html#random-permutations-cross-validation-a-k-a-shuffle-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "kf42 = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "ss = ShuffleSplit(n_splits=3, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train42, test42 = kfoldize(kf42,rn)\n",
    "train123, test123 = kfoldize(ss,rn)\n",
    "\n",
    "fig,ax = plt.subplots(1,2, figsize=(15,5), sharey=True)\n",
    "ax[0].scatter(x=\"x\",y=\"val\",c=\"b\",label=\"train\",s=15,data=train42) \n",
    "ax[0].scatter(x=\"x\",y=\"val\",c=\"r\",label=\"test\",s=15,data=test42)\n",
    "ax[1].scatter(x=\"x\",y=\"val\",c=\"b\",label=\"train\",s=15,data=train123)\n",
    "ax[1].scatter(x=\"x\",y=\"val\",c=\"r\",label=\"test\",s=15,data=test123)\n",
    "ax[0].set_ylabel(\"Kfold\")\n",
    "ax[0].set_xlabel(\"feature\")\n",
    "ax[0].set_title(\"Shuffled KFold with random state 42\")\n",
    "ax[1].set_ylabel(\"Kfold\")\n",
    "ax[1].set_xlabel(\"feature\")\n",
    "ax[1].set_title(\"ShuffleSplit with random state 42 and 50% samples in the test set\")\n",
    "plt.suptitle(\"Comparison of KFold and ShuffleSplit\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave One Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "kf42 = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "loo = LeaveOneOut()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train42, test42 = kfoldize(kf42,rn)\n",
    "train123, test123 = kfoldize(loo,rn)\n",
    "\n",
    "fig,ax = plt.subplots(1,2, figsize=(15,5), sharey=True)\n",
    "ax[0].scatter(x=\"x\",y=\"val\",c=\"b\",label=\"train\",s=15,data=train42) \n",
    "ax[0].scatter(x=\"x\",y=\"val\",c=\"r\",label=\"test\",s=15,data=test42)\n",
    "ax[1].scatter(x=\"x\",y=\"val\",c=\"b\",label=\"train\",s=15,data=train123)\n",
    "ax[1].scatter(x=\"x\",y=\"val\",c=\"r\",label=\"test\",s=15,data=test123)\n",
    "#ax[1].scatter(x=\"x\",y=\"val\",c=\"k\",label=\"test second run\",s=15,data=test123_2)\n",
    "ax[0].set_ylabel(\"Kfold\")\n",
    "ax[0].set_xlabel(\"feature\")\n",
    "ax[0].set_title(\"Shuffled KFold with random state 42\")\n",
    "ax[1].set_ylabel(\"Kfold\")\n",
    "ax[1].set_xlabel(\"feature\")\n",
    "ax[1].set_title(\"LeaveOneOut on range 1 to 25\")\n",
    "plt.suptitle(\"Comparison of KFold and LeaveOneOut\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leave One Out делает то, что и заявлено, оставляет только одно наблюдение в качестве тестового образца.\n",
    "\n",
    "Документация Scikit обсуждает эту тему и предлагает: «Как правило, большинство авторов и эмпирические данные предполагают, что 5- или 10-кратная перекрестная проверка должна быть предпочтительнее LOO».\n",
    "Дополнительная информация: https://scikit-learn.org/stable/modules/cross_validation.html#leave-one-out-loo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Leave P Out\n",
    "https://scikit-learn.org/stable/modules/cross_validation.html#leave-p-out-lpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeavePOut\n",
    "\n",
    "kf42 = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "lpo = LeavePOut(p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train42, test42 = kfoldize(kf42,rn)\n",
    "train123, test123 = kfoldize(lpo,rn)\n",
    "\n",
    "fig,ax = plt.subplots(1,2, figsize=(15,5), sharey=True)\n",
    "ax[0].scatter(x=\"x\",y=\"val\",c=\"b\",label=\"train\",s=15,data=train42) \n",
    "ax[0].scatter(x=\"x\",y=\"val\",c=\"r\",label=\"test\",s=15,data=test42)\n",
    "ax[1].scatter(x=\"x\",y=\"val\",c=\"b\",label=\"train\",s=15,data=train123)\n",
    "ax[1].scatter(x=\"x\",y=\"val\",c=\"r\",label=\"test\",s=15,data=test123)\n",
    "ax[0].set_ylabel(\"Kfold\")\n",
    "ax[0].set_xlabel(\"feature\")\n",
    "ax[0].set_title(\"Shuffled KFold with random state 42\")\n",
    "ax[1].set_ylabel(\"Kfold\")\n",
    "ax[1].set_xlabel(\"feature\")\n",
    "ax[1].set_title(\"LeavePOut with p = 2 on range 1 to 25\")\n",
    "plt.suptitle(\"Comparison of KFold and LeavePOut\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leave P out создает комбинацию ${n \\choose p}$, поэтому в нашем примере ${25 \\choose 2} = 300$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Заключение\n",
    "Мы рассмотрели, как работают методы Sklearn `Kfold`. Мы видим, что они разбивают данные на `n` наборов. Каждый из признаков будет появляться один раз в тестовом наборе и `n-1` раз в обучающем наборе. Вы также можете использовать `ShuffleSplit` или `RepeatedKFold`, если хотите иметь разное распределение между train и test наборами данных.\n",
    "\n",
    "В обычном KFold каждая группа(fold) будет содержать `1/n` значений в обучающем наборе и `n-1/n` значений в проверочном наборе. Таким образом, для `n=2` 50% будут в тестовом наборе, `n=3` 33%, `n=4` 25% и т. д.\n",
    "\n",
    "Мы можем либо разбить данные в порядке их появления, используя `shuffle=False`, либо случайным образом, используя `shuffle=True` и опционально указав `random_state`. Наличие одного и того же случайного состояния (random_state) всегда приведет к одному и тому же разделению тестовых и обучающих данных.\n",
    "\n",
    "Вам не нужно разделять данные вручную, и вы можете применять только методы `cross-validate` или `cross-val-score`. Данные будут разделены на заднем плане, и вы получите окончательную оценку.\n",
    "\n",
    "Важной концепцией является StratifiedKFold, который гарантирует, что соотношение целевых переменных останется одинаковым в обучающем и тестовом наборах. Это не означает, что соотношение признаков будет одинаковым. Если одно из разделений показывает необычайно низкую или высокую оценку, это означает, что разделение может повлиять на результаты модели."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
